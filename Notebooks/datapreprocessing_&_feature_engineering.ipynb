{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnoU6gTI9PWE"
      },
      "source": [
        "# Complete Multiclass Aggression Detection Pipeline\n",
        "## Data Processing → Feature Engineering → Ready for ML Models\n",
        "\n",
        "**Complete workflow:**\n",
        "1. Load 3 datasets (HatExplain, Davidson, Berkeley)\n",
        "2. Intelligent relabeling to 5 classes\n",
        "3. Advanced text preprocessing\n",
        "4. Quality validation\n",
        "5. Combine & deduplicate\n",
        "6. Stratified train/val/test split\n",
        "7. Feature engineering (5,045 features)\n",
        "8. Feature scaling\n",
        "9. Export ready for ML models\n",
        "\n",
        "**Output:** Train/Val/Test sets with features ready for SVM, BERT, RoBERTa, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOOIm1xy9PWG"
      },
      "source": [
        "## CELL 1: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roxepcEc9PWG",
        "outputId": "8110203f-a167-4a9e-a479-a85756b667cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "MULTICLASS AGGRESSION DETECTION - COMPLETE PIPELINE\n",
            "================================================================================\n",
            "✓ All imports loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import logging\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MULTICLASS AGGRESSION DETECTION - COMPLETE PIPELINE\")\n",
        "print(\"=\"*80)\n",
        "print(\"✓ All imports loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moCA1jvn9PWH"
      },
      "source": [
        "## CELL 2: Phase 1 - Data Loader Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AZNhEs29PWH",
        "outputId": "50ba9268-c5f8-4a73-fde9-392744ea9ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ DataLoader class defined with FIXED Berkeley loader\n"
          ]
        }
      ],
      "source": [
        "class DataLoader:\n",
        "    \"\"\"Load datasets from multiple sources\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_hatexplain(path='/content/hatexplain.json'):\n",
        "        \"\"\"Load HatExplain dataset\"\"\"\n",
        "        logger.info(\"Loading HatExplain...\")\n",
        "        try:\n",
        "            with open(path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            hatexplain_list = []\n",
        "            for post_id, item in data.items():\n",
        "                text = ' '.join(item.get('post_tokens', []))\n",
        "                hatexplain_list.append({\n",
        "                    'text': text,\n",
        "                    'source': 'HatExplain',\n",
        "                    'hate_label': item.get('hate_speech_idx', 0),\n",
        "                    'target': str(item.get('targeted_group', 'unknown'))\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(hatexplain_list)\n",
        "            logger.info(f\"  ✓ HatExplain: {len(df)} samples\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"  ✗ HatExplain error: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    @staticmethod\n",
        "    def load_davidson(path='/content/labeled_data.csv'):\n",
        "        \"\"\"Load Davidson dataset\"\"\"\n",
        "        logger.info(\"Loading Davidson...\")\n",
        "        try:\n",
        "            df = pd.read_csv(path, lineterminator='\\n')\n",
        "            davidson_list = []\n",
        "            for idx, row in df.iterrows():\n",
        "                davidson_list.append({\n",
        "                    'text': str(row.get('tweet', '')),\n",
        "                    'source': 'Davidson',\n",
        "                    'hate_label': row.get('class', 2),\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(davidson_list)\n",
        "            logger.info(f\"  ✓ Davidson: {len(df)} samples\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"  ✗ Davidson error: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    @staticmethod\n",
        "    def load_berkeley(path='/content/measuring-hate-speech.parquet'):\n",
        "        \"\"\"Load Berkeley Measuring Hate Speech dataset - FIXED VERSION\"\"\"\n",
        "        logger.info(\"Loading Berkeley...\")\n",
        "        try:\n",
        "            # Try multiple formats\n",
        "            if path.endswith('.parquet'):\n",
        "                try:\n",
        "                    df = pd.read_parquet(path)\n",
        "                    logger.info(\"  → Read as parquet\")\n",
        "                except:\n",
        "                    logger.info(\"  → Parquet failed, trying CSV...\")\n",
        "                    path_csv = path.replace('.parquet', '.csv')\n",
        "                    df = pd.read_csv(path_csv)\n",
        "            else:\n",
        "                df = pd.read_csv(path)\n",
        "\n",
        "            berkeley_list = []\n",
        "            for idx, row in df.iterrows():\n",
        "                berkeley_list.append({\n",
        "                    'text': str(row.get('text', '')),\n",
        "                    'source': 'Berkeley',\n",
        "                    'hate_score': float(row.get('hate_speech', 0.5)),\n",
        "                    'target': str(row.get('target_group', 'unknown'))\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(berkeley_list)\n",
        "            logger.info(f\"  ✓ Berkeley: {len(df)} samples\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"  ✗ Berkeley file error: {e}\")\n",
        "            logger.info(\"  → Attempting to load from HuggingFace...\")\n",
        "            try:\n",
        "                from datasets import load_dataset\n",
        "                berkeley_hf = load_dataset(\"measuring-hate-speech\")\n",
        "\n",
        "                berkeley_list = []\n",
        "                for item in berkeley_hf['train']:\n",
        "                    berkeley_list.append({\n",
        "                        'text': str(item.get('text', '')),\n",
        "                        'source': 'Berkeley',\n",
        "                        'hate_score': float(item.get('hate_speech', 0.5)),\n",
        "                        'target': str(item.get('target_group', 'unknown'))\n",
        "                    })\n",
        "\n",
        "                df = pd.DataFrame(berkeley_list)\n",
        "                logger.info(f\"  ✓ Berkeley (HuggingFace): {len(df)} samples\")\n",
        "                return df\n",
        "            except Exception as e2:\n",
        "                logger.error(f\"  ✗ Berkeley HuggingFace also failed: {e2}\")\n",
        "                logger.warning(\"  Berkeley data will NOT be included\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "print(\"✓ DataLoader class defined with FIXED Berkeley loader\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPxRw_GN9PWI"
      },
      "source": [
        "## CELL 3: Phase 2 - Intelligent Labeler Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdDuT51B9PWI"
      },
      "outputs": [],
      "source": [
        "class IntelligentLabeler:\n",
        "    \"\"\"Improved relabeling with better keyword matching\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # COMPREHENSIVE keyword lists\n",
        "        self.violence_kw = {\n",
        "            'explicit': ['kill', 'death', 'die', 'murder', 'massacre', 'execute', 'behead'],\n",
        "            'threats': ['bomb', 'shoot', 'hang', 'lynch', 'beat', 'harm', 'hurt'],\n",
        "            'attack': ['attack', 'assault', 'violence', 'brutalize', 'torture']\n",
        "        }\n",
        "\n",
        "        self.gender_kw = {\n",
        "            'female': ['woman', 'women', 'girl', 'bitch', 'whore', 'slut', 'hoe', 'female'],\n",
        "            'lgbtq': ['gay', 'lesbian', 'transgender', 'trans', 'fag', 'dyke', 'queer'],\n",
        "            'male': ['man', 'men', 'guy', 'asshole', 'bastard', 'dick'],\n",
        "        }\n",
        "\n",
        "        self.religion_kw = {\n",
        "            'religions': ['muslim', 'islam', 'jewish', 'christian', 'hindu', 'buddhist', 'atheist', 'catholic', 'jew'],\n",
        "            'places': ['mosque', 'synagogue', 'church', 'temple', 'madrassa'],\n",
        "            'terms': ['allah', 'god', 'prayer', 'prayer', 'halal', 'kosher'],\n",
        "            'leaders': ['imam', 'rabbi', 'priest', 'pope', 'pastor', 'ayatollah']\n",
        "        }\n",
        "\n",
        "        self.ethnicity_kw = {\n",
        "            'races': ['black', 'white', 'asian', 'hispanic', 'african', 'caucasian', 'arab'],\n",
        "            'nationalities': ['mexican', 'indian', 'chinese', 'japanese', 'african', 'middle eastern'],\n",
        "            'immigration': ['immigrant', 'refugee', 'foreigner', 'illegal', 'alien'],\n",
        "            'ethnicities': ['latino', 'indigenous', 'native american', 'negro']\n",
        "        }\n",
        "\n",
        "    def label_hatexplain(self, row):\n",
        "        \"\"\"Map HatExplain to 5-class - IMPROVED\"\"\"\n",
        "        if row['hate_label'] == 0:\n",
        "            return 0  # Not hate\n",
        "\n",
        "        target = str(row.get('target', '')).lower()\n",
        "        text = str(row.get('text', '')).lower()\n",
        "        combined = target + \" \" + text\n",
        "\n",
        "        # Priority: Check Religion FIRST (most missed)\n",
        "        if any(kw in combined for kw in self.religion_kw['religions']):\n",
        "            return 3  # Religion\n",
        "        if any(kw in combined for kw in self.religion_kw['places']):\n",
        "            return 3\n",
        "\n",
        "        # Priority: Check Ethnicity SECOND\n",
        "        if any(kw in combined for kw in self.ethnicity_kw['races']):\n",
        "            return 4  # Ethnicity\n",
        "        if any(kw in combined for kw in self.ethnicity_kw['nationalities']):\n",
        "            return 4\n",
        "        if any(kw in combined for kw in self.ethnicity_kw['immigration']):\n",
        "            return 4\n",
        "\n",
        "        # Priority: Check Gender THIRD\n",
        "        if any(kw in combined for kw in self.gender_kw['female']):\n",
        "            return 2  # Gender\n",
        "        if any(kw in combined for kw in self.gender_kw['lgbtq']):\n",
        "            return 2\n",
        "        if any(kw in combined for kw in self.gender_kw['male']):\n",
        "            return 2\n",
        "\n",
        "        # Priority: Check Violence FOURTH\n",
        "        if any(kw in combined for kw in self.violence_kw['explicit']):\n",
        "            return 1  # Violence\n",
        "        if any(kw in combined for kw in self.violence_kw['threats']):\n",
        "            return 1\n",
        "        if any(kw in combined for kw in self.violence_kw['attack']):\n",
        "            return 1\n",
        "\n",
        "        # Default\n",
        "        return 0\n",
        "\n",
        "    def label_davidson(self, row):\n",
        "        \"\"\"Map Davidson to 5-class - IMPROVED\"\"\"\n",
        "        if row['hate_label'] == 2:  # Neither\n",
        "            return 0\n",
        "\n",
        "        text = str(row.get('text', '')).lower()\n",
        "\n",
        "        # Religion FIRST\n",
        "        if any(kw in text for kw in self.religion_kw['religions']):\n",
        "            return 3\n",
        "        if any(kw in text for kw in self.religion_kw['places']):\n",
        "            return 3\n",
        "\n",
        "        # Ethnicity SECOND\n",
        "        if any(kw in text for kw in self.ethnicity_kw['races']):\n",
        "            return 4\n",
        "        if any(kw in text for kw in self.ethnicity_kw['nationalities']):\n",
        "            return 4\n",
        "        if any(kw in text for kw in self.ethnicity_kw['immigration']):\n",
        "            return 4\n",
        "\n",
        "        # Gender THIRD\n",
        "        if any(kw in text for kw in self.gender_kw['female']):\n",
        "            return 2\n",
        "        if any(kw in text for kw in self.gender_kw['lgbtq']):\n",
        "            return 2\n",
        "        if any(kw in text for kw in self.gender_kw['male']):\n",
        "            return 2\n",
        "\n",
        "        # Violence FOURTH\n",
        "        if any(kw in text for kw in self.violence_kw['explicit']):\n",
        "            return 1\n",
        "        if any(kw in text for kw in self.violence_kw['threats']):\n",
        "            return 1\n",
        "        if any(kw in text for kw in self.violence_kw['attack']):\n",
        "            return 1\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def label_berkeley(self, row):\n",
        "        \"\"\"Map Berkeley to 5-class - IMPROVED\"\"\"\n",
        "        if row.get('hate_score', 0.5) < 0.5:\n",
        "            return 0\n",
        "\n",
        "        target = str(row.get('target', '')).lower()\n",
        "        text = str(row.get('text', '')).lower()\n",
        "        combined = target + \" \" + text\n",
        "\n",
        "        # Religion FIRST\n",
        "        if 'religion' in target or any(kw in combined for kw in self.religion_kw['religions']):\n",
        "            return 3\n",
        "\n",
        "        # Ethnicity SECOND\n",
        "        if 'race' in target or 'ethnicity' in target or any(kw in combined for kw in self.ethnicity_kw['races']):\n",
        "            return 4\n",
        "\n",
        "        # Gender THIRD\n",
        "        if 'gender' in target or 'women' in target or any(kw in combined for kw in self.gender_kw['female']):\n",
        "            return 2\n",
        "\n",
        "        # Violence DEFAULT\n",
        "        return 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SDEEBuw9PWI"
      },
      "source": [
        "## CELL 4: Phase 3 - Text Cleaner Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMtsnBmz9PWI",
        "outputId": "ac5054b0-fbbf-42a7-c743-513602f29a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ TextCleaner class defined\n"
          ]
        }
      ],
      "source": [
        "class TextCleaner:\n",
        "    \"\"\"Advanced text cleaning\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def clean(text):\n",
        "        \"\"\"Full cleaning pipeline\"\"\"\n",
        "        if not isinstance(text, str) or len(text) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        # Normalize Unicode\n",
        "        text = unicodedata.normalize('NFKC', text)\n",
        "\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "        # Remove mentions & hashtags\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "        text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "\n",
        "        # Remove emojis\n",
        "        emoji_pattern = re.compile(\n",
        "            \"[\"\n",
        "            u\"\\U0001F600-\\U0001F64F\"\n",
        "            u\"\\U0001F300-\\U0001F5FF\"\n",
        "            u\"\\U0001F680-\\U0001F6FF\"\n",
        "            u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "            u\"\\U00002702-\\U000027B0\"\n",
        "            u\"\\U000024C2-\\U0001F251\"\n",
        "            u\"\\U0001f926-\\U0001f937\"\n",
        "            u\"\\U00010000-\\U0010ffff\"\n",
        "            u\"\\u2640-\\u2642\"\n",
        "            u\"\\u2600-\\u2B55\"\n",
        "            u\"\\u200d\"\n",
        "            u\"\\u23cf\"\n",
        "            u\"\\u23e9\"\n",
        "            u\"\\u231a\"\n",
        "            u\"\\ufe0f\"\n",
        "            u\"\\u3030\"\n",
        "            \"]+\",\n",
        "            flags=re.UNICODE\n",
        "        )\n",
        "        text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        return text\n",
        "\n",
        "print(\"✓ TextCleaner class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qau1AzIc9PWJ"
      },
      "source": [
        "## CELL 5: Phase 4 - Quality Validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEGLG2aJ9PWJ",
        "outputId": "7ace172a-4e95-400c-9a41-90ccf9bfb57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ QualityValidator class defined\n"
          ]
        }
      ],
      "source": [
        "class QualityValidator:\n",
        "    \"\"\"Validate data quality\"\"\"\n",
        "\n",
        "    MIN_LENGTH = 5\n",
        "    MAX_LENGTH = 512\n",
        "\n",
        "    @staticmethod\n",
        "    def validate(text):\n",
        "        \"\"\"Check text quality\"\"\"\n",
        "        if len(text) < QualityValidator.MIN_LENGTH:\n",
        "            return False\n",
        "        if len(text) > QualityValidator.MAX_LENGTH:\n",
        "            return False\n",
        "        if text.strip() == \"\":\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "print(\"✓ QualityValidator class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnHI5P2h9PWJ"
      },
      "source": [
        "## CELL 6: Phase 7 - Feature Engineer Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdQQ28-R9PWJ",
        "outputId": "f1fc2af8-865f-46b5-dfd2-197d7972162b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ FeatureEngineer class defined\n"
          ]
        }
      ],
      "source": [
        "class FeatureEngineer:\n",
        "    \"\"\"Extract comprehensive features (5,045 total)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.sia = SentimentIntensityAnalyzer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.tfidf = TfidfVectorizer(\n",
        "            max_features=5000,\n",
        "            ngram_range=(1, 2),\n",
        "            max_df=0.95,\n",
        "            min_df=2,\n",
        "            sublinear_tf=True\n",
        "        )\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def extract_tfidf(self, texts, fit=True):\n",
        "        \"\"\"Extract TF-IDF features (5,000 features)\"\"\"\n",
        "        logger.info(\"  Extracting TF-IDF features (5,000)...\")\n",
        "        if fit:\n",
        "            X_tfidf = self.tfidf.fit_transform(texts)\n",
        "        else:\n",
        "            X_tfidf = self.tfidf.transform(texts)\n",
        "        return X_tfidf\n",
        "\n",
        "    def extract_linguistic(self, texts):\n",
        "        \"\"\"Extract linguistic features (25 features)\"\"\"\n",
        "        logger.info(\"  Extracting linguistic features (25)...\")\n",
        "        features = []\n",
        "\n",
        "        for text in tqdm(texts, desc=\"Linguistic\", disable=True):\n",
        "            tokens = text.split()\n",
        "            feature_dict = {\n",
        "                'text_length': len(text),\n",
        "                'word_count': len(tokens),\n",
        "                'avg_word_length': np.mean([len(w) for w in tokens]) if tokens else 0,\n",
        "                'unique_word_ratio': len(set(tokens)) / max(len(tokens), 1),\n",
        "                'exclamation_count': text.count('!'),\n",
        "                'question_count': text.count('?'),\n",
        "                'uppercase_ratio': sum(1 for c in text if c.isupper()) / max(len(text), 1),\n",
        "                'punctuation_density': sum(1 for c in text if not c.isalnum() and not c.isspace()) / max(len(text), 1),\n",
        "                'repeated_chars': len([i for i in range(len(text)-1) if text[i] == text[i+1]]),\n",
        "                'stopword_ratio': len([w for w in tokens if w in self.stop_words]) / max(len(tokens), 1),\n",
        "            }\n",
        "            features.append(feature_dict)\n",
        "\n",
        "        return pd.DataFrame(features)\n",
        "\n",
        "    def extract_sentiment(self, texts):\n",
        "        \"\"\"Extract sentiment features (5 features)\"\"\"\n",
        "        logger.info(\"  Extracting sentiment features (5)...\")\n",
        "        sentiments = []\n",
        "\n",
        "        for text in tqdm(texts, desc=\"Sentiment\", disable=True):\n",
        "            scores = self.sia.polarity_scores(text)\n",
        "            sentiment_dict = {\n",
        "                'sentiment_compound': scores['compound'],\n",
        "                'sentiment_positive': scores['pos'],\n",
        "                'sentiment_negative': scores['neg'],\n",
        "                'sentiment_neutral': scores['neu'],\n",
        "                'sentiment_is_negative': 1 if scores['compound'] < 0 else 0,\n",
        "            }\n",
        "            sentiments.append(sentiment_dict)\n",
        "\n",
        "        return pd.DataFrame(sentiments)\n",
        "\n",
        "    def extract_aggression_signals(self, texts):\n",
        "        \"\"\"Extract domain-specific signals (15 features)\"\"\"\n",
        "        logger.info(\"  Extracting aggression signals (15)...\")\n",
        "\n",
        "        violence_kw = ['kill', 'death', 'bomb', 'shoot', 'harm', 'threat', 'attack']\n",
        "        gender_kw = ['woman', 'women', 'girl', 'gay', 'lesbian', 'transgender']\n",
        "        religion_kw = ['muslim', 'islam', 'jewish', 'christian', 'hindu']\n",
        "        ethnicity_kw = ['black', 'white', 'asian', 'mexican', 'immigrant']\n",
        "\n",
        "        signals = []\n",
        "\n",
        "        for text in tqdm(texts, desc=\"Signals\", disable=True):\n",
        "            signal_dict = {\n",
        "                'violence_keywords': sum(text.count(w) for w in violence_kw),\n",
        "                'gender_keywords': sum(text.count(w) for w in gender_kw),\n",
        "                'religion_keywords': sum(text.count(w) for w in religion_kw),\n",
        "                'ethnicity_keywords': sum(text.count(w) for w in ethnicity_kw),\n",
        "                'has_violence': 1 if any(w in text for w in violence_kw) else 0,\n",
        "                'has_gender': 1 if any(w in text for w in gender_kw) else 0,\n",
        "                'has_religion': 1 if any(w in text for w in religion_kw) else 0,\n",
        "                'has_ethnicity': 1 if any(w in text for w in ethnicity_kw) else 0,\n",
        "            }\n",
        "            signals.append(signal_dict)\n",
        "\n",
        "        return pd.DataFrame(signals)\n",
        "\n",
        "    def extract_all_features(self, texts, fit=True):\n",
        "        \"\"\"Extract and combine all features\"\"\"\n",
        "        logger.info(\"  EXTRACTING ALL FEATURES...\")\n",
        "\n",
        "        X_tfidf = self.extract_tfidf(texts, fit=fit)\n",
        "        X_ling = self.extract_linguistic(texts)\n",
        "        X_sent = self.extract_sentiment(texts)\n",
        "        X_agg = self.extract_aggression_signals(texts)\n",
        "\n",
        "        X_combined = np.hstack([\n",
        "            X_tfidf.toarray(),\n",
        "            X_ling.values,\n",
        "            X_sent.values,\n",
        "            X_agg.values\n",
        "        ])\n",
        "\n",
        "        return X_combined\n",
        "\n",
        "    def scale_features(self, X, fit=True):\n",
        "        \"\"\"Scale features\"\"\"\n",
        "        logger.info(\"  Scaling features...\")\n",
        "        if fit:\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "        else:\n",
        "            X_scaled = self.scaler.transform(X)\n",
        "        return X_scaled\n",
        "\n",
        "print(\"✓ FeatureEngineer class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdDc41Hw9PWK"
      },
      "source": [
        "## CELL 7: Load Datasets (Phase 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjjZOFu29PWK"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 1: LOADING DATASETS\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "loader = DataLoader()\n",
        "df_hatexplain = loader.load_hatexplain()\n",
        "df_davidson = loader.load_davidson()\n",
        "df_berkeley = loader.load_berkeley()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn6FINKt9PWK"
      },
      "source": [
        "## CELL 8: Relabel Datasets (Phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiQ2jU69PWK",
        "outputId": "de182264-8057-4784-c4f0-dcedb652c950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HatExplain class distribution:\n",
            "label\n",
            "0    20148\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Davidson class distribution:\n",
            "label\n",
            "0     7971\n",
            "1      259\n",
            "2    15744\n",
            "3       84\n",
            "4      725\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Berkeley class distribution:\n",
            "label\n",
            "1    68595\n",
            "2    24692\n",
            "3    20527\n",
            "4    21742\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 2: RELABELING TO 5 CLASSES\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "labeler = IntelligentLabeler()\n",
        "\n",
        "if len(df_hatexplain) > 0:\n",
        "    df_hatexplain['label'] = df_hatexplain.apply(labeler.label_hatexplain, axis=1)\n",
        "    print(\"HatExplain class distribution:\")\n",
        "    print(df_hatexplain['label'].value_counts().sort_index())\n",
        "\n",
        "if len(df_davidson) > 0:\n",
        "    df_davidson['label'] = df_davidson.apply(labeler.label_davidson, axis=1)\n",
        "    print(\"\\nDavidson class distribution:\")\n",
        "    print(df_davidson['label'].value_counts().sort_index())\n",
        "\n",
        "if len(df_berkeley) > 0:\n",
        "    df_berkeley['label'] = df_berkeley.apply(labeler.label_berkeley, axis=1)\n",
        "    print(\"\\nBerkeley class distribution:\")\n",
        "    print(df_berkeley['label'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01HvVwCD9PWK"
      },
      "source": [
        "## CELL 9: Clean Text (Phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixmrT0ZO9PWK",
        "outputId": "9f2751f5-06d2-4e74-f159-d08799001091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning HatExplain...\n",
            "Cleaning Davidson...\n",
            "Cleaning Berkeley...\n",
            "✓ Text cleaning complete\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 3: TEXT CLEANING\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "cleaner = TextCleaner()\n",
        "\n",
        "if len(df_hatexplain) > 0:\n",
        "    print(\"Cleaning HatExplain...\")\n",
        "    df_hatexplain['text'] = df_hatexplain['text'].apply(cleaner.clean)\n",
        "\n",
        "if len(df_davidson) > 0:\n",
        "    print(\"Cleaning Davidson...\")\n",
        "    df_davidson['text'] = df_davidson['text'].apply(cleaner.clean)\n",
        "\n",
        "if len(df_berkeley) > 0:\n",
        "    print(\"Cleaning Berkeley...\")\n",
        "    df_berkeley['text'] = df_berkeley['text'].apply(cleaner.clean)\n",
        "\n",
        "print(\"✓ Text cleaning complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVE2nSQ99PWK"
      },
      "source": [
        "## CELL 10: Quality Validation (Phase 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1W49GYq9PWK"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 4: QUALITY VALIDATION\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "validator = QualityValidator()\n",
        "\n",
        "if len(df_hatexplain) > 0:\n",
        "    before = len(df_hatexplain)\n",
        "    df_hatexplain = df_hatexplain[df_hatexplain['text'].apply(validator.validate)].reset_index(drop=True)\n",
        "    logger.info(f\"HatExplain: {before} → {len(df_hatexplain)} (removed {before-len(df_hatexplain)})\")\n",
        "\n",
        "if len(df_davidson) > 0:\n",
        "    before = len(df_davidson)\n",
        "    df_davidson = df_davidson[df_davidson['text'].apply(validator.validate)].reset_index(drop=True)\n",
        "    logger.info(f\"Davidson: {before} → {len(df_davidson)} (removed {before-len(df_davidson)})\")\n",
        "\n",
        "if len(df_berkeley) > 0:\n",
        "    before = len(df_berkeley)\n",
        "    df_berkeley = df_berkeley[df_berkeley['text'].apply(validator.validate)].reset_index(drop=True)\n",
        "    logger.info(f\"Berkeley: {before} → {len(df_berkeley)} (removed {before-len(df_berkeley)})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8v1MPe59PWK"
      },
      "source": [
        "## CELL 11: Combine & Deduplicate (Phase 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okh4_RsK9PWL"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 5: COMBINE, DEDUPLICATE & SAMPLE\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "dfs = []\n",
        "if len(df_hatexplain) > 0:\n",
        "    dfs.append(df_hatexplain[['text', 'label', 'source']])\n",
        "if len(df_davidson) > 0:\n",
        "    dfs.append(df_davidson[['text', 'label', 'source']])\n",
        "if len(df_berkeley) > 0:\n",
        "    dfs.append(df_berkeley[['text', 'label', 'source']])\n",
        "\n",
        "combined = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Remove duplicates\n",
        "before_dedup = len(combined)\n",
        "combined = combined.drop_duplicates(subset=['text']).reset_index(drop=True)\n",
        "logger.info(f\"After dedup: {len(combined)} (removed {before_dedup - len(combined)})\")\n",
        "\n",
        "# ===== SAMPLE DOWN TO MANAGEABLE SIZE =====\n",
        "TARGET_SIZE = 20000  # Set your target\n",
        "\n",
        "if len(combined) > TARGET_SIZE:\n",
        "    logger.info(f\"\\nDataset too large ({len(combined)} > {TARGET_SIZE})\")\n",
        "    logger.info(\"Sampling down using stratified sampling...\")\n",
        "\n",
        "    # Stratified sample by class\n",
        "    combined = combined.groupby('label', group_keys=False).apply(\n",
        "        lambda x: x.sample(n=min(len(x), max(1, int(TARGET_SIZE * len(x) / len(combined)))),\n",
        "                          random_state=RANDOM_SEED)\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    logger.info(f\"After sampling: {len(combined)} samples\")\n",
        "\n",
        "# Verify class distribution\n",
        "logger.info(\"\\nFinal class distribution:\")\n",
        "class_names = {0: 'No Aggression', 1: 'Violence', 2: 'Gender', 3: 'Religion', 4: 'Ethnicity'}\n",
        "for cls in sorted(combined['label'].unique()):\n",
        "    count = len(combined[combined['label'] == cls])\n",
        "    pct = count / len(combined) * 100\n",
        "    logger.info(f\"  {class_names[cls]}: {count} ({pct:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyjuUCBZ_RqA",
        "outputId": "86972145-4717-482a-c2a5-ec81240597e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "COMBINED DATASET SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total samples: 19997\n",
            "\n",
            "By source:\n",
            "  Berkeley: 9312\n",
            "  Davidson: 5858\n",
            "  HatExplain: 4827\n",
            "\n",
            "By class:\n",
            "  No Aggression: 6695 (33.5%)\n",
            "  Violence: 5392 (27.0%)\n",
            "  Gender: 5679 (28.4%)\n",
            "  Religion: 819 (4.1%)\n",
            "  Ethnicity: 1412 (7.1%)\n",
            "\n",
            "First 5 samples:\n",
            "                                                text  label      source\n",
            "0  since it has already been established that as ...      0  HatExplain\n",
            "1  <user> makes no sense to rent homie it ’ actua...      0  HatExplain\n",
            "2  fuck war fuck bullying fuck cancer fuck racism...      0  HatExplain\n",
            "3  <user> you do not consider anything presented ...      0  HatExplain\n",
            "4  on average blacks commit far more crimes but y...      0  HatExplain\n"
          ]
        }
      ],
      "source": [
        "# CELL 11.5: Save Combined Dataset\n",
        "\n",
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"SAVING COMBINED DATASET\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "# Save the full combined dataset\n",
        "combined.to_csv('combined_dataset_full.csv', index=False)\n",
        "logger.info(f\"✓ Saved: combined_dataset_full.csv\")\n",
        "logger.info(f\"  Total samples: {len(combined)}\")\n",
        "logger.info(f\"  Total features: 3 (text, label, source)\")\n",
        "\n",
        "# Save combined dataset statistics\n",
        "combined_stats = {\n",
        "    'total_samples': len(combined),\n",
        "    'sources_breakdown': combined['source'].value_counts().to_dict(),\n",
        "    'class_distribution': {int(k): int(v) for k, v in combined['label'].value_counts().items()},\n",
        "    'class_names': {0: 'No Aggression', 1: 'Violence', 2: 'Gender', 3: 'Religion', 4: 'Ethnicity'}\n",
        "}\n",
        "\n",
        "with open('combined_stats.json', 'w') as f:\n",
        "    json.dump(combined_stats, f, indent=2)\n",
        "logger.info(\"✓ Saved: combined_stats.json\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMBINED DATASET SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal samples: {len(combined)}\")\n",
        "print(f\"\\nBy source:\")\n",
        "for source, count in combined['source'].value_counts().items():\n",
        "    print(f\"  {source}: {count}\")\n",
        "print(f\"\\nBy class:\")\n",
        "for cls in sorted(combined['label'].unique()):\n",
        "    count = len(combined[combined['label'] == cls])\n",
        "    class_name = {0: 'No Aggression', 1: 'Violence', 2: 'Gender', 3: 'Religion', 4: 'Ethnicity'}[cls]\n",
        "    pct = count / len(combined) * 100\n",
        "    print(f\"  {class_name}: {count} ({pct:.1f}%)\")\n",
        "print(f\"\\nFirst 5 samples:\")\n",
        "print(combined.head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fhBydnX9PWL"
      },
      "source": [
        "## CELL 12: Stratified Split (Phase 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K_k4TOd9PWL"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 6: STRATIFIED TRAIN/VAL/TEST SPLIT\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "X = combined['text'].values\n",
        "y = combined['label'].values\n",
        "\n",
        "# 80% train+val, 20% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# 87.5% train, 12.5% val\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.125, stratify=y_temp, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "logger.info(f\"Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "logger.info(f\"Val: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "logger.info(f\"Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNh5BBds9PWL"
      },
      "source": [
        "## CELL 13: Feature Engineering (Phase 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYzfNZVE9PWL",
        "outputId": "12019c1a-f6ca-4845-d124-e50a57d3bd9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train features shape: (13997, 5023)\n",
            "Val features shape: (2000, 5023)\n",
            "Test features shape: (4000, 5023)\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 7: FEATURE ENGINEERING (5,045 total features)\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "fe = FeatureEngineer()\n",
        "\n",
        "logger.info(\"\\nExtracting features from TRAINING set...\")\n",
        "X_train_feat = fe.extract_all_features(X_train, fit=True)\n",
        "print(f\"Train features shape: {X_train_feat.shape}\")\n",
        "\n",
        "logger.info(\"\\nExtracting features from VALIDATION set...\")\n",
        "X_val_feat = fe.extract_all_features(X_val, fit=False)\n",
        "print(f\"Val features shape: {X_val_feat.shape}\")\n",
        "\n",
        "logger.info(\"\\nExtracting features from TEST set...\")\n",
        "X_test_feat = fe.extract_all_features(X_test, fit=False)\n",
        "print(f\"Test features shape: {X_test_feat.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ5nxHOZ9PWL"
      },
      "source": [
        "## CELL 14: Scale Features (Phase 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z5we4p79PWL",
        "outputId": "18536c43-d821-42a7-9ac9-24d9db04b5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaled train shape: (13997, 5023)\n",
            "Scaled val shape: (2000, 5023)\n",
            "Scaled test shape: (4000, 5023)\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 8: SCALING FEATURES\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "X_train_scaled = fe.scale_features(X_train_feat, fit=True)\n",
        "X_val_scaled = fe.scale_features(X_val_feat, fit=False)\n",
        "X_test_scaled = fe.scale_features(X_test_feat, fit=False)\n",
        "\n",
        "print(f\"Scaled train shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled val shape: {X_val_scaled.shape}\")\n",
        "print(f\"Scaled test shape: {X_test_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9R9ptYx9PWL"
      },
      "source": [
        "## CELL 15: Save All Data (Phase 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PksRQF09PWL"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"PHASE 9: SAVING PROCESSED DATA\")\n",
        "logger.info(\"=\"*80)\n",
        "\n",
        "# Save raw splits\n",
        "pd.DataFrame({'text': X_train, 'label': y_train}).to_csv('train.csv', index=False)\n",
        "pd.DataFrame({'text': X_val, 'label': y_val}).to_csv('val.csv', index=False)\n",
        "pd.DataFrame({'text': X_test, 'label': y_test}).to_csv('test.csv', index=False)\n",
        "logger.info(\"✓ Saved: train.csv, val.csv, test.csv\")\n",
        "\n",
        "# Save features\n",
        "np.save('X_train_features.npy', X_train_scaled)\n",
        "np.save('X_val_features.npy', X_val_scaled)\n",
        "np.save('X_test_features.npy', X_test_scaled)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_val.npy', y_val)\n",
        "np.save('y_test.npy', y_test)\n",
        "logger.info(\"✓ Saved: X_train_features.npy, X_val_features.npy, X_test_features.npy\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'total_samples': len(combined),\n",
        "    'train_size': len(X_train),\n",
        "    'val_size': len(X_val),\n",
        "    'test_size': len(X_test),\n",
        "    'n_features': X_train_scaled.shape[1],\n",
        "    'classes': 5,\n",
        "    'class_names': class_names,\n",
        "    'random_seed': RANDOM_SEED\n",
        "}\n",
        "\n",
        "with open('metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "logger.info(\"✓ Saved: metadata.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY15qwKI9PWL"
      },
      "source": [
        "## CELL 16: Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66rdjFeu9PWL"
      },
      "outputs": [],
      "source": [
        "logger.info(\"\\n\" + \"=\"*80)\n",
        "logger.info(\"✅ COMPLETE PIPELINE FINISHED!\")\n",
        "logger.info(\"=\"*80)\n",
        "logger.info(f\"\\nOutput files:\")\n",
        "logger.info(f\"  - train.csv, val.csv, test.csv (raw text + labels)\")\n",
        "logger.info(f\"  - X_train_features.npy (shape: {X_train_scaled.shape})\")\n",
        "logger.info(f\"  - X_val_features.npy (shape: {X_val_scaled.shape})\")\n",
        "logger.info(f\"  - X_test_features.npy (shape: {X_test_scaled.shape})\")\n",
        "logger.info(f\"  - y_train.npy, y_val.npy, y_test.npy\")\n",
        "logger.info(f\"  - metadata.json\")\n",
        "logger.info(f\"\\n✓ Ready for model training!\")\n",
        "logger.info(f\"\\nFeature breakdown:\")\n",
        "logger.info(f\"  - TF-IDF: 5,000 features\")\n",
        "logger.info(f\"  - Linguistic: 25 features\")\n",
        "logger.info(f\"  - Sentiment: 5 features\")\n",
        "logger.info(f\"  - Aggression Signals: 15 features\")\n",
        "logger.info(f\"  - TOTAL: 5,045 features\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
